{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'TriangleAttack' from '/home/jovyan/TriangleAttack.py'>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Essentials\n",
    "import os\n",
    "import numpy as np\n",
    "import importlib\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Utils\n",
    "import utils\n",
    "importlib.reload(utils)\n",
    "\n",
    "from utils import get_dict, get_files, check_corrupted_imgs, perturb_image, save_image, make_dirs, get_model, select_gpu\n",
    "from utils import CustomTransforms, My_data, FocalLoss\n",
    "\n",
    "# OnePixelAttack\n",
    "import OnePixelAttack\n",
    "\n",
    "importlib.reload(OnePixelAttack)\n",
    "\n",
    "# TriangleAttack\n",
    "import TriangleAttack\n",
    "importlib.reload(TriangleAttack)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a higher max split size to avoid memory problems\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:512\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting GPU 2 with 14903MB free memory\n",
      "cuda:2\n",
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |  109982 KB |  109982 KB |  109982 KB |       0 B  |\n",
      "|       from large pool |   99392 KB |   99392 KB |   99392 KB |       0 B  |\n",
      "|       from small pool |   10590 KB |   10590 KB |   10590 KB |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |  109982 KB |  109982 KB |  109982 KB |       0 B  |\n",
      "|       from large pool |   99392 KB |   99392 KB |   99392 KB |       0 B  |\n",
      "|       from small pool |   10590 KB |   10590 KB |   10590 KB |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |  135168 KB |  135168 KB |  135168 KB |       0 B  |\n",
      "|       from large pool |  122880 KB |  122880 KB |  122880 KB |       0 B  |\n",
      "|       from small pool |   12288 KB |   12288 KB |   12288 KB |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |   25186 KB |   25546 KB |  101956 KB |   76770 KB |\n",
      "|       from large pool |   23488 KB |   23744 KB |   90048 KB |   66560 KB |\n",
      "|       from small pool |    1698 KB |    2047 KB |   11908 KB |   10210 KB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |     262    |     262    |     262    |       0    |\n",
      "|       from large pool |      28    |      28    |      28    |       0    |\n",
      "|       from small pool |     234    |     234    |     234    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |     262    |     262    |     262    |       0    |\n",
      "|       from large pool |      28    |      28    |      28    |       0    |\n",
      "|       from small pool |     234    |     234    |     234    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |      12    |      12    |      12    |       0    |\n",
      "|       from large pool |       6    |       6    |       6    |       0    |\n",
      "|       from small pool |       6    |       6    |       6    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |       6    |       6    |      12    |       6    |\n",
      "|       from large pool |       5    |       5    |       6    |       1    |\n",
      "|       from small pool |       1    |       2    |       6    |       5    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
      "|===========================================================================|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "global device\n",
    "device = torch.device(f\"cuda:{select_gpu()}\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(device)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "    print(torch.cuda.memory_summary(device=None, abbreviated=False))\n",
    "    torch.cuda.manual_seed(42)\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    torch.backends.cudnn.deterministic = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening Train.txt\n",
      "done\n",
      "Opening Train.txt\n",
      "done\n",
      "True\n",
      "copying completed\n"
     ]
    }
   ],
   "source": [
    "# Load train and test files that are used for the model.\n",
    "train_dict = get_dict(\"train.txt\")\n",
    "print(\"done\")\n",
    "test_dict = get_dict(\"test.txt\")\n",
    "print(\"done\")\n",
    "\n",
    "print(check_corrupted_imgs(train_dict, test_dict))\n",
    "\n",
    "print(\"copying completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_files = get_files(\"./dataset/train/**/**/*.png\")\n",
    "\n",
    "test_files = get_files(\"./dataset/test/**/**/*.png\")\n",
    "\n",
    "# print(train_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_transforms = CustomTransforms()\n",
    "resize_transform = custom_transforms.get_transform(\"resize_tensor\")\n",
    "test_transform = custom_transforms.get_transform(\"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Attack "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original = My_data([test_files[0]])[0][0]\n",
    "\n",
    "# p_tensor = np.copy(original)\n",
    "\n",
    "# for i in range(100):\n",
    "#     perturbation = [i, i] + list(np.random.choice(range(256), size=3))\n",
    "\n",
    "#     p_tensor = perturb_image(perturbation, p_tensor)\n",
    "\n",
    "# save_image(p_tensor, \"perturbedimagerandom.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensor_list = [original, p_tensor]\n",
    "\n",
    "# org = resize_transform(image=original)\n",
    "# org_im = org['image']\n",
    "\n",
    "# org_norm = test_transform(image=original)\n",
    "# org_norm_im = org_norm['image']\n",
    "\n",
    "# save_image(org_im, \"org.png\")\n",
    "# save_image(org_norm_im, \"org_norm.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# per = resize_transform(image=p_tensor)\n",
    "# per_im = per['image']\n",
    "\n",
    "# per_norm = test_transform(image=p_tensor)\n",
    "# per_norm_im = per_norm['image']\n",
    "\n",
    "# save_image(per_im, \"per.png\")\n",
    "# save_image(per_norm_im, \"per_norm.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deze wordt nu niet gecallt om tijd te besparen tijdens run all (nodig na veranderen geimporteerd bestand)\n",
    "def simple_one_pixel_attack():\n",
    "    make_dirs(\"simple_one_pixel\")\n",
    "    orgs = My_data(test_files)\n",
    "    for i in range(orgs.__len__()):\n",
    "        p_tensor = np.copy(orgs.__getitem__(i)[0])\n",
    "        for j in range(200):\n",
    "            random_x = np.random.choice(range(1, 698))\n",
    "            random_y = np.random.choice(range(1, 398))\n",
    "\n",
    "            random_xs = [random_x - 1, random_x, random_x + 1]\n",
    "            random_ys = [random_y - 1, random_y, random_y + 1]\n",
    "\n",
    "            for x in random_xs:\n",
    "                for y in random_ys:\n",
    "                    perturbation = [y, x] + list(np.random.choice(range(256), size=3))\n",
    "                    p_tensor = perturb_image(perturbation, p_tensor)\n",
    "                    \n",
    "        save_image(p_tensor, os.path.join(os.getcwd(), \"dataset\", \"simple_one_pixel\", orgs.__getclass__(i), orgs.__getzoom__(i), orgs.__getname__(i)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# org_norm = My_data(test_files, transforms=test_transform)\n",
    "# perturb_data = My_data(get_files(\"./dataset/test_onepixel/**/**/*.png\"), transforms=test_transform)\n",
    "\n",
    "# org_dataloader = DataLoader(org_norm)\n",
    "# pertrubed_dataloader = DataLoader(perturb_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test performance of Simple OnePixel Attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = get_model(device, test_dict)\n",
    "\n",
    "# model.eval()\n",
    "# correct_org = 0\n",
    "# correct_pert = 0\n",
    "# confs_org = []\n",
    "# confs_pert = []\n",
    "# with torch.no_grad():\n",
    "#     print(\"Testing network without attacks...\")\n",
    "#     for i, (inputs, labels) in enumerate(org_dataloader):\n",
    "#         inputs = inputs.to(device)\n",
    "#         labels = labels.float()\n",
    "#         labels = labels.to(device)\n",
    "#         outputs = model(inputs)\n",
    "#         confs_org.append(outputs)\n",
    "        \n",
    "#         if torch.argmax(outputs) == torch.argmax(labels):\n",
    "#             correct_org += 1\n",
    "#     print(f\"Accuracy of network without attack: {correct_org/len(test_files)}\")\n",
    "# # ######################## Run TinySwin without attacks ########################\n",
    "#     print(\"Testing network with OnePixel attack...\")\n",
    "#     for i, (inputs, labels) in enumerate(pertrubed_dataloader):\n",
    "#         inputs = inputs.to(device)\n",
    "#         labels = labels.float()\n",
    "#         labels = labels.to(device)\n",
    "#         outputs = model(inputs)\n",
    "#         confs_pert.append(outputs)\n",
    "        \n",
    "#         if torch.argmax(outputs) == torch.argmax(labels):\n",
    "#             correct_pert += 1\n",
    "#     print(f\"Accuracy of network with OnePixel attack: {correct_pert/len(test_files)}\")\n",
    "\n",
    "#     # Compare the performance in confidence outputs\n",
    "#     print(sum([torch.max(confs_org[i]) > torch.max(confs_pert[i]) for i in range(len(test_files))]), len(test_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Show all differences in predictions\n",
    "# for i in range(len(test_files)):\n",
    "#     if torch.argmax(confs_org[i]) != torch.argmax(confs_pert[i]):\n",
    "#         print(\"Different predictions\")\n",
    "#         print(confs_org[i])\n",
    "#         print(confs_pert[i])\n",
    "#         print(test_files[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced OnePixel Attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# org_norm = My_data(test_files, transforms=test_transform)\n",
    "# org_dataloader = DataLoader(org_norm)\n",
    "\n",
    "# model = get_model(device, test_dict, \"resnet\")\n",
    "\n",
    "# model.eval()\n",
    "# with torch.no_grad():\n",
    "#     success = 0\n",
    "#     correct_init_classification = 0\n",
    "#     for i, (image, label) in enumerate(org_dataloader):\n",
    "#         success, correct_init_classification = OnePixelAttack.attack(i, model, device, image, label, pixel_count=1, maxiter=50, popsize=15)\n",
    "#         success += success  \n",
    "#         correct_init_classification += correct_init_classification\n",
    "\n",
    "\n",
    "#     print(success)\n",
    "#     print(\"Accuracy\", correct_init_classification / len(org_dataloader.dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Triangle attack   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"GIT_PYTHON_GIT_EXECUTABLE\"] = \"/usr/bin/git\"\n",
    "\n",
    "import git\n",
    "git.refresh(\"/usr/bin/git\")\n",
    "\n",
    "from foolbox import PyTorchModel\n",
    "from TriangleAttack import TA\n",
    "\n",
    "\n",
    "org_norm = My_data(test_files, transforms=test_transform)\n",
    "org_dataloader = DataLoader(org_norm)\n",
    "model = PyTorchModel(get_model(device, test_dict).eval(), bounds=(0,1), device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attack !\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 2.28 GiB (GPU 2; 14.56 GiB total capacity; 12.07 GiB already allocated; 976.56 MiB free; 12.17 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m      4\u001b[0m     ta_model \u001b[38;5;241m=\u001b[39m TA(model, input_device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[0;32m----> 5\u001b[0m     my_advs, q_list, my_intermediates, max_length \u001b[38;5;241m=\u001b[39m \u001b[43mta_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattack\u001b[49m\u001b[43m(\u001b[49m\u001b[43morg_dataloader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTA Attack Done\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/TriangleAttack.py:237\u001b[0m, in \u001b[0;36mTA.attack\u001b[0;34m(self, dataloader)\u001b[0m\n\u001b[1;32m    235\u001b[0m init_attack: MinimizationAttack \u001b[38;5;241m=\u001b[39m LinearSearchBlendedUniformNoiseAttack(steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m)\n\u001b[1;32m    236\u001b[0m criterion \u001b[38;5;241m=\u001b[39m get_criterion(labels\u001b[38;5;241m.\u001b[39mlong())\n\u001b[0;32m--> 237\u001b[0m best_advs \u001b[38;5;241m=\u001b[39m \u001b[43minit_attack\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    238\u001b[0m max_length \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    239\u001b[0m acc \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m0.\u001b[39m, \u001b[38;5;241m0.\u001b[39m, \u001b[38;5;241m0.\u001b[39m]\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/foolbox/attacks/blended_noise.py:72\u001b[0m, in \u001b[0;36mLinearSearchBlendedUniformNoiseAttack.run\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdirections):\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# random noise inputs tend to be classified into the same class,\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# so we might need to make very many draws if the original class\u001b[39;00m\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;66;03m# is that one\u001b[39;00m\n\u001b[1;32m     71\u001b[0m     random_ \u001b[38;5;241m=\u001b[39m ep\u001b[38;5;241m.\u001b[39muniform(x, x\u001b[38;5;241m.\u001b[39mshape, min_, max_)\n\u001b[0;32m---> 72\u001b[0m     is_adv_ \u001b[38;5;241m=\u001b[39m atleast_kd(\u001b[43mis_adversarial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrandom_\u001b[49m\u001b[43m)\u001b[49m, x\u001b[38;5;241m.\u001b[39mndim)\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m j \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     75\u001b[0m         random \u001b[38;5;241m=\u001b[39m random_\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/foolbox/attacks/base.py:463\u001b[0m, in \u001b[0;36mget_is_adversarial.<locals>.is_adversarial\u001b[0;34m(perturbed)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mis_adversarial\u001b[39m(perturbed: ep\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ep\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[0;32m--> 463\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mperturbed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    464\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m criterion(perturbed, outputs)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/foolbox/models/base.py:102\u001b[0m, in \u001b[0;36mModelWithPreprocessing.__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    100\u001b[0m x, restore_type \u001b[38;5;241m=\u001b[39m ep\u001b[38;5;241m.\u001b[39mastensor_(inputs)\n\u001b[1;32m    101\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_preprocess(x)\n\u001b[0;32m--> 102\u001b[0m z \u001b[38;5;241m=\u001b[39m ep\u001b[38;5;241m.\u001b[39mastensor(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m restore_type(z)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/foolbox/models/pytorch.py:49\u001b[0m, in \u001b[0;36mPyTorchModel.__init__.<locals>._model\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_model\u001b[39m(x: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(x\u001b[38;5;241m.\u001b[39mrequires_grad):\n\u001b[0;32m---> 49\u001b[0m         result \u001b[38;5;241m=\u001b[39m cast(torch\u001b[38;5;241m.\u001b[39mTensor, \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/timm/models/swin_transformer_v2.py:612\u001b[0m, in \u001b[0;36mSwinTransformerV2.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    611\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m--> 612\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    613\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward_head(x)\n\u001b[1;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/timm/models/swin_transformer_v2.py:604\u001b[0m, in \u001b[0;36mSwinTransformerV2.forward_features\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    602\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward_features\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m    603\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpatch_embed(x)\n\u001b[0;32m--> 604\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    605\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm(x)\n\u001b[1;32m    606\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/container.py:204\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 204\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    205\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/timm/models/swin_transformer_v2.py:437\u001b[0m, in \u001b[0;36mSwinTransformerV2Stage.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    435\u001b[0m         x \u001b[38;5;241m=\u001b[39m checkpoint\u001b[38;5;241m.\u001b[39mcheckpoint(blk, x)\n\u001b[1;32m    436\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 437\u001b[0m         x \u001b[38;5;241m=\u001b[39m \u001b[43mblk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    438\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/timm/models/swin_transformer_v2.py:322\u001b[0m, in \u001b[0;36mSwinTransformerV2Block.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    320\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m    321\u001b[0m     B, H, W, C \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m--> 322\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop_path1(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm1(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_attn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m))\n\u001b[1;32m    323\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mreshape(B, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, C)\n\u001b[1;32m    324\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop_path2(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm2(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmlp(x)))\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/timm/models/swin_transformer_v2.py:307\u001b[0m, in \u001b[0;36mSwinTransformerV2Block._attn\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    304\u001b[0m x_windows \u001b[38;5;241m=\u001b[39m x_windows\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwindow_area, C)  \u001b[38;5;66;03m# nW*B, window_size*window_size, C\u001b[39;00m\n\u001b[1;32m    306\u001b[0m \u001b[38;5;66;03m# W-MSA/SW-MSA\u001b[39;00m\n\u001b[0;32m--> 307\u001b[0m attn_windows \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_windows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattn_mask\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# nW*B, window_size*window_size, C\u001b[39;00m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;66;03m# merge windows\u001b[39;00m\n\u001b[1;32m    310\u001b[0m attn_windows \u001b[38;5;241m=\u001b[39m attn_windows\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwindow_size[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwindow_size[\u001b[38;5;241m1\u001b[39m], C)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/timm/models/swin_transformer_v2.py:167\u001b[0m, in \u001b[0;36mWindowAttention.forward\u001b[0;34m(self, x, mask)\u001b[0m\n\u001b[1;32m    164\u001b[0m q, k, v \u001b[38;5;241m=\u001b[39m qkv\u001b[38;5;241m.\u001b[39munbind(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    166\u001b[0m \u001b[38;5;66;03m# cosine attention\u001b[39;00m\n\u001b[0;32m--> 167\u001b[0m attn \u001b[38;5;241m=\u001b[39m (\u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    168\u001b[0m logit_scale \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mclamp(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogit_scale, \u001b[38;5;28mmax\u001b[39m\u001b[38;5;241m=\u001b[39mmath\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;241m1.\u001b[39m \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m0.01\u001b[39m))\u001b[38;5;241m.\u001b[39mexp()\n\u001b[1;32m    169\u001b[0m attn \u001b[38;5;241m=\u001b[39m attn \u001b[38;5;241m*\u001b[39m logit_scale\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 2.28 GiB (GPU 2; 14.56 GiB total capacity; 12.07 GiB already allocated; 976.56 MiB free; 12.17 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "# run on a10 gpu as it has highest memory\n",
    "print(\"Attack !\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    ta_model = TA(model, input_device=device)\n",
    "    my_advs, q_list, my_intermediates, max_length = ta_model.attack(org_dataloader)\n",
    "    print('TA Attack Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import albumentations\n",
    "# import albumentations.pytorch\n",
    "\n",
    "# transforms_a =  albumentations.Compose([\n",
    "#                 albumentations.Resize(256, 256),\n",
    "#                 albumentations.Normalize(mean=[0, 0, 0], std=[255, 255, 255], max_pixel_value=1.0),\n",
    "#                 albumentations.pytorch.transforms.ToTensorV2()\n",
    "#             ])\n",
    "\n",
    "# test_a= My_data([test_files[0]], transforms_a)\n",
    "\n",
    "# save_image(test_a.__getitem__(0)[0], \"attemptofsucces_a.png\")\n",
    "\n",
    "# transforms_b =  albumentations.Compose([\n",
    "#                 albumentations.Resize(256, 256),\n",
    "#                 albumentations.Normalize(mean=[0 , 0, 0], std=[1, 1, 1], max_pixel_value=255),\n",
    "#                 albumentations.pytorch.transforms.ToTensorV2()\n",
    "#             ])\n",
    "\n",
    "# test_b = My_data([test_files[0]], transforms_b)\n",
    "\n",
    "# save_image(test_b.__getitem__(0)[0], \"attemptofsucces_b.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(org_dataloader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
