{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'TriangleAttack' from '/home/jovyan/TriangleAttack.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Essentials\n",
    "import os\n",
    "import numpy as np\n",
    "import importlib\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Utils\n",
    "import utils\n",
    "importlib.reload(utils)\n",
    "\n",
    "from utils import get_dict, get_files, check_corrupted_imgs, perturb_image, save_image, make_dirs, get_model, select_gpu\n",
    "from utils import CustomTransforms, My_data, FocalLoss\n",
    "\n",
    "# OnePixelAttack\n",
    "import OnePixelAttack\n",
    "\n",
    "importlib.reload(OnePixelAttack)\n",
    "\n",
    "# TriangleAttack\n",
    "import TriangleAttack\n",
    "importlib.reload(TriangleAttack)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a higher max split size to avoid memory problems\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:512\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting GPU 0 with 22729MB free memory\n",
      "cuda:0\n",
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
      "|===========================================================================|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "global device\n",
    "device = torch.device(f\"cuda:{select_gpu()}\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(device)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "    print(torch.cuda.memory_summary(device=None, abbreviated=False))\n",
    "    torch.cuda.manual_seed(42)\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    torch.backends.cudnn.deterministic = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening Train.txt\n",
      "done\n",
      "Opening Train.txt\n",
      "done\n",
      "True\n",
      "copying completed\n"
     ]
    }
   ],
   "source": [
    "# Load train and test files that are used for the model.\n",
    "train_dict = get_dict(\"train.txt\")\n",
    "print(\"done\")\n",
    "test_dict = get_dict(\"test.txt\")\n",
    "print(\"done\")\n",
    "\n",
    "print(check_corrupted_imgs(train_dict, test_dict))\n",
    "\n",
    "print(\"copying completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_files = get_files(\"./dataset/train/**/**/*.png\")\n",
    "\n",
    "test_files = get_files(\"./dataset/test/**/**/*.png\")\n",
    "\n",
    "# print(train_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_transforms = CustomTransforms()\n",
    "resize_transform = custom_transforms.get_transform(\"resize_tensor\")\n",
    "test_transform = custom_transforms.get_transform(\"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Attack "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original = My_data([test_files[0]])[0][0]\n",
    "\n",
    "# p_tensor = np.copy(original)\n",
    "\n",
    "# for i in range(100):\n",
    "#     perturbation = [i, i] + list(np.random.choice(range(256), size=3))\n",
    "\n",
    "#     p_tensor = perturb_image(perturbation, p_tensor)\n",
    "\n",
    "# save_image(p_tensor, \"perturbedimagerandom.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensor_list = [original, p_tensor]\n",
    "\n",
    "# org = resize_transform(image=original)\n",
    "# org_im = org['image']\n",
    "\n",
    "# org_norm = test_transform(image=original)\n",
    "# org_norm_im = org_norm['image']\n",
    "\n",
    "# save_image(org_im, \"org.png\")\n",
    "# save_image(org_norm_im, \"org_norm.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# per = resize_transform(image=p_tensor)\n",
    "# per_im = per['image']\n",
    "\n",
    "# per_norm = test_transform(image=p_tensor)\n",
    "# per_norm_im = per_norm['image']\n",
    "\n",
    "# save_image(per_im, \"per.png\")\n",
    "# save_image(per_norm_im, \"per_norm.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deze wordt nu niet gecallt om tijd te besparen tijdens run all (nodig na veranderen geimporteerd bestand)\n",
    "def simple_one_pixel_attack():\n",
    "    make_dirs(\"simple_one_pixel\")\n",
    "    orgs = My_data(test_files)\n",
    "    for i in range(orgs.__len__()):\n",
    "        p_tensor = np.copy(orgs.__getitem__(i)[0])\n",
    "        for j in range(200):\n",
    "            random_x = np.random.choice(range(1, 698))\n",
    "            random_y = np.random.choice(range(1, 398))\n",
    "\n",
    "            random_xs = [random_x - 1, random_x, random_x + 1]\n",
    "            random_ys = [random_y - 1, random_y, random_y + 1]\n",
    "\n",
    "            for x in random_xs:\n",
    "                for y in random_ys:\n",
    "                    perturbation = [y, x] + list(np.random.choice(range(256), size=3))\n",
    "                    p_tensor = perturb_image(perturbation, p_tensor)\n",
    "                    \n",
    "        save_image(p_tensor, os.path.join(os.getcwd(), \"dataset\", \"simple_one_pixel\", orgs.__getclass__(i), orgs.__getzoom__(i), orgs.__getname__(i)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# org_norm = My_data(test_files, transforms=test_transform)\n",
    "# perturb_data = My_data(get_files(\"./dataset/test_onepixel/**/**/*.png\"), transforms=test_transform)\n",
    "\n",
    "# org_dataloader = DataLoader(org_norm)\n",
    "# pertrubed_dataloader = DataLoader(perturb_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test performance of Simple OnePixel Attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = get_model(device, test_dict)\n",
    "\n",
    "# model.eval()\n",
    "# correct_org = 0\n",
    "# correct_pert = 0\n",
    "# confs_org = []\n",
    "# confs_pert = []\n",
    "# with torch.no_grad():\n",
    "#     print(\"Testing network without attacks...\")\n",
    "#     for i, (inputs, labels) in enumerate(org_dataloader):\n",
    "#         inputs = inputs.to(device)\n",
    "#         labels = labels.float()\n",
    "#         labels = labels.to(device)\n",
    "#         outputs = model(inputs)\n",
    "#         confs_org.append(outputs)\n",
    "        \n",
    "#         if torch.argmax(outputs) == torch.argmax(labels):\n",
    "#             correct_org += 1\n",
    "#     print(f\"Accuracy of network without attack: {correct_org/len(test_files)}\")\n",
    "# # ######################## Run TinySwin without attacks ########################\n",
    "#     print(\"Testing network with OnePixel attack...\")\n",
    "#     for i, (inputs, labels) in enumerate(pertrubed_dataloader):\n",
    "#         inputs = inputs.to(device)\n",
    "#         labels = labels.float()\n",
    "#         labels = labels.to(device)\n",
    "#         outputs = model(inputs)\n",
    "#         confs_pert.append(outputs)\n",
    "        \n",
    "#         if torch.argmax(outputs) == torch.argmax(labels):\n",
    "#             correct_pert += 1\n",
    "#     print(f\"Accuracy of network with OnePixel attack: {correct_pert/len(test_files)}\")\n",
    "\n",
    "#     # Compare the performance in confidence outputs\n",
    "#     print(sum([torch.max(confs_org[i]) > torch.max(confs_pert[i]) for i in range(len(test_files))]), len(test_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Show all differences in predictions\n",
    "# for i in range(len(test_files)):\n",
    "#     if torch.argmax(confs_org[i]) != torch.argmax(confs_pert[i]):\n",
    "#         print(\"Different predictions\")\n",
    "#         print(confs_org[i])\n",
    "#         print(confs_pert[i])\n",
    "#         print(test_files[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced OnePixel Attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# org_norm = My_data(test_files, transforms=test_transform)\n",
    "# org_dataloader = DataLoader(org_norm)\n",
    "\n",
    "# model = get_model(device, test_dict, \"resnet\")\n",
    "\n",
    "# model.eval()\n",
    "# with torch.no_grad():\n",
    "#     success = 0\n",
    "#     correct_init_classification = 0\n",
    "#     for i, (image, label) in enumerate(org_dataloader):\n",
    "#         success, correct_init_classification = OnePixelAttack.attack(i, model, device, image, label, pixel_count=1, maxiter=50, popsize=15)\n",
    "#         success += success  \n",
    "#         correct_init_classification += correct_init_classification\n",
    "\n",
    "\n",
    "#     print(success)\n",
    "#     print(\"Accuracy\", correct_init_classification / len(org_dataloader.dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Triangle attack   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/.local/lib/python3.8/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"GIT_PYTHON_GIT_EXECUTABLE\"] = \"/usr/bin/git\"\n",
    "\n",
    "import git\n",
    "git.refresh(\"/usr/bin/git\")\n",
    "\n",
    "from foolbox import PyTorchModel\n",
    "from TriangleAttack import TA\n",
    "\n",
    "\n",
    "org_norm = My_data(test_files, transforms=test_transform)\n",
    "org_dataloader = DataLoader(org_norm)\n",
    "model = PyTorchModel(get_model(device, test_dict).eval(), bounds=(0,1), device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attack !\n",
      "torch.Size([777])\n",
      "loading best_advs\n",
      "\n",
      " tensor([[[0.6706, 0.7137, 0.7294,  ..., 0.7490, 0.7373, 0.6784],\n",
      "         [0.7098, 0.7294, 0.7373,  ..., 0.7451, 0.7373, 0.6706],\n",
      "         [0.7059, 0.7333, 0.7373,  ..., 0.7020, 0.7412, 0.6745],\n",
      "         ...,\n",
      "         [0.7725, 0.7843, 0.7882,  ..., 0.8157, 0.8235, 0.8157],\n",
      "         [0.7804, 0.8039, 0.8078,  ..., 0.8275, 0.8275, 0.8157],\n",
      "         [0.7765, 0.7804, 0.8078,  ..., 0.8275, 0.8196, 0.8000]],\n",
      "\n",
      "        [[0.5804, 0.5961, 0.6353,  ..., 0.7216, 0.6980, 0.6549],\n",
      "         [0.6000, 0.6118, 0.6353,  ..., 0.7059, 0.6980, 0.6667],\n",
      "         [0.6118, 0.6196, 0.6471,  ..., 0.6667, 0.7216, 0.6745],\n",
      "         ...,\n",
      "         [0.8039, 0.8157, 0.8196,  ..., 0.8824, 0.8941, 0.8824],\n",
      "         [0.8157, 0.8314, 0.8275,  ..., 0.8863, 0.8863, 0.8824],\n",
      "         [0.8078, 0.7961, 0.8275,  ..., 0.8863, 0.8824, 0.8706]],\n",
      "\n",
      "        [[0.6275, 0.6667, 0.7020,  ..., 0.7137, 0.7137, 0.6745],\n",
      "         [0.6549, 0.6824, 0.6863,  ..., 0.6980, 0.7137, 0.6784],\n",
      "         [0.6627, 0.6980, 0.7020,  ..., 0.6745, 0.7412, 0.6824],\n",
      "         ...,\n",
      "         [0.7608, 0.7922, 0.8118,  ..., 0.8000, 0.8157, 0.8196],\n",
      "         [0.7725, 0.8118, 0.8431,  ..., 0.8039, 0.8118, 0.8196],\n",
      "         [0.7647, 0.7804, 0.8471,  ..., 0.8039, 0.8078, 0.8000]]],\n",
      "       device='cuda:0') \n",
      "\n",
      "[1/777]:"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'TA' object has no attribute 'get_label'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m      5\u001b[0m     ta_model \u001b[38;5;241m=\u001b[39m TA(model, input_device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[0;32m----> 6\u001b[0m     my_advs, q_list, my_intermediates, max_length \u001b[38;5;241m=\u001b[39m \u001b[43mta_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattack\u001b[49m\u001b[43m(\u001b[49m\u001b[43morg_dataloader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTA Attack Done\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/TriangleAttack.py:281\u001b[0m, in \u001b[0;36mTA.attack\u001b[0;34m(self, dataloader)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_x_hat_in_2d_total \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    279\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_x_hat_in_2d_clamp \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 281\u001b[0m x_adv, q, intermediate \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_x_hat_arbitary\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnewaxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43minit_x\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbest_advs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnewaxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim_num\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdim_num\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    284\u001b[0m x_adv_list[i] \u001b[38;5;241m=\u001b[39m x_adv[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    285\u001b[0m diff \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnorm(x_adv[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m-\u001b[39m \u001b[38;5;28minput\u001b[39m, p\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m) \u001b[38;5;241m/\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mside_length \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39msqrt(\u001b[38;5;241m3\u001b[39m))\n",
      "File \u001b[0;32m~/TriangleAttack.py:196\u001b[0m, in \u001b[0;36mTA.get_x_hat_arbitary\u001b[0;34m(self, x_o, net, original_label, init_x, dim_num)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_x_hat_arbitary\u001b[39m(\u001b[38;5;28mself\u001b[39m,x_o: torch\u001b[38;5;241m.\u001b[39mTensor, net: torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mModule, original_label, init_x\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,dim_num\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m):\n\u001b[0;32m--> 196\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_label\u001b[49m(net(x_o)) \u001b[38;5;241m!=\u001b[39m original_label:\n\u001b[1;32m    197\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m x_o, \u001b[38;5;241m1001\u001b[39m, [[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0.\u001b[39m], [\u001b[38;5;241m1001\u001b[39m, \u001b[38;5;241m0.\u001b[39m]]\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m init_x \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'TA' object has no attribute 'get_label'"
     ]
    }
   ],
   "source": [
    "# run on a10 gpu as it has highest memory\n",
    "print(\"Attack !\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    ta_model = TA(model, input_device=device)\n",
    "    my_advs, q_list, my_intermediates, max_length = ta_model.attack(org_dataloader)\n",
    "    print('TA Attack Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_advs[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import albumentations\n",
    "# import albumentations.pytorch\n",
    "\n",
    "# transforms_a =  albumentations.Compose([\n",
    "#                 albumentations.Resize(256, 256),\n",
    "#                 albumentations.Normalize(mean=[0, 0, 0], std=[255, 255, 255], max_pixel_value=1.0),\n",
    "#                 albumentations.pytorch.transforms.ToTensorV2()\n",
    "#             ])\n",
    "\n",
    "# test_a= My_data([test_files[0]], transforms_a)\n",
    "\n",
    "# save_image(test_a.__getitem__(0)[0], \"attemptofsucces_a.png\")\n",
    "\n",
    "# transforms_b =  albumentations.Compose([\n",
    "#                 albumentations.Resize(256, 256),\n",
    "#                 albumentations.Normalize(mean=[0 , 0, 0], std=[1, 1, 1], max_pixel_value=255),\n",
    "#                 albumentations.pytorch.transforms.ToTensorV2()\n",
    "#             ])\n",
    "\n",
    "# test_b = My_data([test_files[0]], transforms_b)\n",
    "\n",
    "# save_image(test_b.__getitem__(0)[0], \"attemptofsucces_b.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(org_dataloader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
